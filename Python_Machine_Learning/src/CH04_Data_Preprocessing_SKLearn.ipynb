{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch04 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A     B     C    D\n",
       "0  1.0   2.0   3.0  4.0\n",
       "1  5.0   6.0   NaN  8.0\n",
       "2  0.0  11.0  12.0  NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dealing with Missing Data\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "# Create a sample dataframe which contains some missing data in some columns\n",
    "# unicode is only needed for python 2.7\n",
    "csv_data = unicode('''A,B,C,D\n",
    "            1.0,2.0,3.0,4.0\n",
    "            5.0,6.0,,8.0\n",
    "            0.0,11.0,12.0,''')\n",
    "df = pd.read_csv(StringIO(csv_data))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    0\n",
      "B    0\n",
      "C    1\n",
      "D    1\n",
      "dtype: int64\n",
      "\n",
      "[[  1.   2.   3.   4.]\n",
      " [  5.   6.  nan   8.]\n",
      " [  0.  11.  12.  nan]]\n",
      "\n",
      "     A    B    C    D\n",
      "0  1.0  2.0  3.0  4.0\n",
      "\n",
      "     A     B\n",
      "0  1.0   2.0\n",
      "1  5.0   6.0\n",
      "2  0.0  11.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A     B     C    D\n",
       "0  1.0   2.0   3.0  4.0\n",
       "1  5.0   6.0   NaN  8.0\n",
       "2  0.0  11.0  12.0  NaN"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for the total number of null values in each column\n",
    "print df.isnull().sum()\n",
    "print ''\n",
    "# underlying values can be always accessed as a numpy array from a pandas dataframe\n",
    "print df.values  \n",
    "print ''\n",
    "# drops the rows having null values\n",
    "print df.dropna()\n",
    "print ''\n",
    "# to drop the columns with null values\n",
    "print df.dropna(axis=1)\n",
    "print ''\n",
    "df.dropna(how='all') # drop all rows where all columns are NAN\n",
    "df.dropna(thresh=4) # have not atleast 4 non-NAN values\n",
    "df.dropna(subset=['C']) # drop from a particular column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1. ,   2. ,   3. ,   4. ],\n",
       "       [  5. ,   6. ,   7.5,   8. ],\n",
       "       [  0. ,  11. ,  12. ,   6. ]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imputing missing values\n",
    "from sklearn.preprocessing import Imputer\n",
    "imr = Imputer(missing_values='NaN', strategy='mean', axis=0) # strategy can be median or most_frequent, \n",
    "# axis = 0 by columns and axis = 1 is by rows.\n",
    "imr.fit(df)\n",
    "imputed_data = imr.transform(df.values)\n",
    "imputed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical features handling - Ordinal or Nominal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   color  size  price   label\n",
      "0  green     1   10.1  class1\n",
      "1    red     2   20.1  class2\n",
      "2   blue     3   30.1  class1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Categorical features handling - Ordinal or Nominal\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_ord_nom = pd.DataFrame([['green', 'M', 10.1, 'class1'],\n",
    "            ['red', 'L', 20.1, 'class2'],\n",
    "            ['blue', 'XL', 30.1, 'class1']])\n",
    "df_ord_nom.columns = [\"color\",\"size\",\"price\", \"label\"]\n",
    "df_ord_nom\n",
    "\n",
    "# define a map for the sizes and then convert them to the numberical values\n",
    "size_mapping = {'M':1, 'L':2, 'XL':3}\n",
    "df_ord_nom['size'] = df_ord_nom['size'].map(size_mapping)\n",
    "print df_ord_nom\n",
    "print ''\n",
    "\n",
    "# doing the reverse mapping\n",
    "reverse_mapping_size = {v:k for k,v in size_mapping.items()}\n",
    "df_ord_nom['size'] = df_ord_nom['size'].map(reverse_mapping_size)\n",
    "print df_ord_nom\n",
    "print ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   color size  price  label\n",
      "0  green    M   10.1      0\n",
      "1    red    L   20.1      1\n",
      "2   blue   XL   30.1      0\n",
      "\n",
      "   color size  price  label\n",
      "0  green    M   10.1      0\n",
      "1    red    L   20.1      1\n",
      "2   blue   XL   30.1      0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert class labels to numerical values\n",
    "class_mapping = {label:idx for idx,label in enumerate(np.unique(df_ord_nom['label']))}\n",
    "df_ord_nom['label'] = df_ord_nom['label'].map(class_mapping)\n",
    "print df_ord_nom\n",
    "print ''\n",
    "\n",
    "#doing the reverse class conversion\n",
    "reverse_class_mapping = {v:k for k,v in class_mapping.items()}\n",
    "df_ord_nom['label'] = df_ord_nom['label'].map(reverse_class_mapping)\n",
    "print df_ord_nom\n",
    "print ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   color size  price  label\n",
      "0  green    M   10.1      0\n",
      "1    red    L   20.1      1\n",
      "2   blue   XL   30.1      0\n",
      "   color size  price  label\n",
      "0  green    M   10.1      0\n",
      "1    red    L   20.1      1\n",
      "2   blue   XL   30.1      0\n"
     ]
    }
   ],
   "source": [
    "# the same thing can be achieved by using Sklearn's LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "class_le = LabelEncoder()\n",
    "df_ord_nom['label'] = class_le.fit_transform(df_ord_nom['label'])\n",
    "print df_ord_nom\n",
    "df_ord_nom['label'] = class_le.inverse_transform(df_ord_nom['label'])\n",
    "print df_ord_nom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### perform One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 10.1]\n",
      " [2 2 20.1]\n",
      " [0 3 30.1]]\n",
      "[[1 1 10.1]\n",
      " [2 2 20.1]\n",
      " [0 3 30.1]]\n"
     ]
    }
   ],
   "source": [
    "# perform one-hot encoding\n",
    "X = df_ord_nom[['color','size', 'price']].values\n",
    "color_le = LabelEncoder()\n",
    "X[:,0] = color_le.fit_transform(X[:,0])\n",
    "print X\n",
    "\n",
    "# instead use the one-hot encoding technique to transform the color column\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(categorical_features=[0]) # can use sparse=False if the toarray() need to be removed\n",
    "ohe.fit_transform(X).toarray()\n",
    "print X\n",
    "\n",
    "# pandas get_dummies only converts the string values to a one hot encoding values\n",
    "# pd.get_dummies(df_ord_nom[['price','color','size']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partitioning the Dataset into train and test - Wine DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "   Class label  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
      "0            1    14.23        1.71  2.43               15.6        127   \n",
      "1            1    13.20        1.78  2.14               11.2        100   \n",
      "2            1    13.16        2.36  2.67               18.6        101   \n",
      "3            1    14.37        1.95  2.50               16.8        113   \n",
      "4            1    13.24        2.59  2.87               21.0        118   \n",
      "\n",
      "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
      "0           2.80        3.06                  0.28             2.29   \n",
      "1           2.65        2.76                  0.26             1.28   \n",
      "2           2.80        3.24                  0.30             2.81   \n",
      "3           3.85        3.49                  0.24             2.18   \n",
      "4           2.80        2.69                  0.39             1.82   \n",
      "\n",
      "   Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
      "0             5.64  1.04                          3.92     1065  \n",
      "1             4.38  1.05                          3.40     1050  \n",
      "2             5.68  1.03                          3.17     1185  \n",
      "3             7.80  0.86                          3.45     1480  \n",
      "4             4.32  1.04                          2.93      735  \n"
     ]
    }
   ],
   "source": [
    "#Partition the dataset into train and test\n",
    "df_wine = pd.read_csv('/Users/tkmacl9/Desktop/Patents_Research_Papers_Personalization/All_Machine_Learning/wine_UCI.csv', header=None)\n",
    "df_wine.columns = ['Class label', 'Alcohol','Malic acid', 'Ash', \n",
    "                   'Alcalinity of ash', 'Magnesium', 'Total phenols', \n",
    "                   'Flavanoids','Nonflavanoid phenols', 'Proanthocyanins', \n",
    "                   'Color intensity', 'Hue', 'OD280/OD315 of diluted wines', 'Proline']\n",
    "\n",
    "print np.unique(df_wine['Class label'])\n",
    "print df_wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124, 13)\n",
      "(54, 13)\n",
      "(124,)\n",
      "(54,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "# iloc provides the specific columns to be picked up\n",
    "X = df_wine.iloc[:,1:].values\n",
    "y = df_wine.iloc[:,0].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "print X_train.shape\n",
    "print X_test.shape\n",
    "print y_train.shape\n",
    "print y_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bringing Features to the same scale - Normalization and Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.72043011  0.20378151]\n",
      " [ 0.31989247  0.08403361]\n",
      " [ 0.60215054  0.71218487]\n",
      " [ 0.57258065  0.56302521]]\n",
      "\n",
      "[[ 0.72849462  0.16386555]\n",
      " [ 0.47311828  0.37394958]\n",
      " [ 0.36021505  0.05042017]\n",
      " [ 0.68010753  0.17647059]]\n"
     ]
    }
   ],
   "source": [
    "# Bringing Features to the same scale - Normalization and Standardization\n",
    "# This is the Normalization - MinMaxScaler which uses the min max scaling \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "stdsc = MinMaxScaler()\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "X_test_std = stdsc.transform(X_test)\n",
    "print X_train_std[:4,:2]\n",
    "print ''\n",
    "print X_test_std[:4,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.91083058 -0.46259897]\n",
      " [-0.95609928 -0.96608672]\n",
      " [ 0.35952243  1.67501572]\n",
      " [ 0.22169539  1.0478643 ]]\n",
      "\n",
      "[[ 0.94841977 -0.63042822]\n",
      " [-0.24190464  0.25288364]\n",
      " [-0.76815332 -1.10741662]\n",
      " [ 0.72288462 -0.57742951]]\n"
     ]
    }
   ],
   "source": [
    "# Bringing Features to the same scale - Normalization and Standardization\n",
    "# This is the Normalization - which uses the min max scaling \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "stdsc = StandardScaler()\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "X_test_std = stdsc.transform(X_test)\n",
    "print X_train_std[:4,:2]\n",
    "print ''\n",
    "print X_test_std[:4,:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Meaningful Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training Accuracy : ', 0.98148148148148151)\n",
      "[-0.38380571 -0.15815566 -0.70038665]\n",
      "\n",
      "[[ 0.27995866  0.          0.         -0.02782167  0.          0.\n",
      "   0.7099735   0.          0.          0.          0.          0.\n",
      "   1.23661684]\n",
      " [-0.64367427 -0.06891062 -0.05719491  0.          0.          0.          0.\n",
      "   0.          0.         -0.92725086  0.05981741  0.         -0.37096993]\n",
      " [ 0.          0.06146911  0.          0.          0.          0.\n",
      "  -0.63712137  0.          0.          0.4985422  -0.35791726 -0.57041736\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# LR intercept runs one vs all classifiers for the 3 classes\n",
    "# LR coefficients generate weights for all 13 wine featurs for all the 3 classes\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(penalty='l1', C=0.1)\n",
    "lr.fit(X_train_std,y_train)\n",
    "print('Training Accuracy : ', lr.score(X_test_std, y_test))\n",
    "print('Training Accuracy : ', lr.score(X_test_std, y_test))\n",
    "print lr.intercept_\n",
    "print ''\n",
    "print lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
